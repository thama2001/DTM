{\n  "cells": [\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "# üöÜ FRAMEWORK FOR INTEGRATING INTELLIGENT TRANSPORTATION SYSTEMS CONCEPTS FOR SRI-LANKA\n",\n        "\n",\n        "## üìä Comprehensive ITS Dashboard & Analytics Platform\n",\n        "\n",\n        "### üéØ Research Outcomes Covered:\n",\n        "1. **üîÑ Multimodal Transport Coordination** - Data synchronization between transport modes\n",\n        "2. **üö¶ Traffic Congestion Prediction** - Random Forest ML-powered forecasting\n",\n        "3. **üìà Operational Insights** - Real-time KPIs and decision support\n",\n        "4. **üåßÔ∏è Weather-Driven Route Optimization** - Monsoon-aware routing\n",\n        "\n",\n        "---\n",\n        "\n",\n        "**Author:** MTDT Research Team  \n",\n        "**Dataset Size:** 75,000+ transport records  \n",\n        "**Coverage:** 12 major hubs across Sri Lanka"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# üì¶ Import Required Libraries\n",\n        "print(\"üîß Setting up environment...\")\n",\n        "\n",\n        "import pandas as pd\n",\n        "import numpy as np\n",\n        "import matplotlib.pyplot as plt\n",\n        "import seaborn as sns\n",\n        "import plotly.express as px\n",\n        "import plotly.graph_objects as go\n",\n        "from plotly.subplots import make_subplots\n",\n        "import networkx as nx\n",\n        "from datetime import datetime, timedelta\n",\n        "import warnings\n",\n        "from sklearn.model_selection import train_test_split, cross_val_score\n",\n        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",\n        "from sklearn.preprocessing import LabelEncoder\n",\n        "from sklearn.metrics import (\n",\n        "    mean_squared_error, mean_absolute_error, r2_score,\n",\n        "    accuracy_score, classification_report, confusion_matrix, f1_score\n",\n        ")\n",\n        "\n",\n        "warnings.filterwarnings('ignore')\n",\n        "np.random.seed(42)\n",\n        "pd.set_option('display.max_columns', None)\n",\n        "\n",\n        "print(\"‚úÖ Environment setup complete!\")"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## üó∫Ô∏è Sri Lanka Transport Network Configuration"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# üöå Transport Modes and Hubs\n",\n        "TRANSPORT_MODES = ['SLTB Bus', 'Private Bus', 'Train (Sri Lanka Railways)',\n",\n        "                   'Three-Wheeler (Tuk-tuk)', 'Taxi (PickMe/Uber)', 'Ferry']\n",\n        "\n",\n        "SRI_LANKA_HUBS = {\n",\n        "    'Colombo Fort': {'lat': 6.9344, 'lon': 79.8428, 'type': 'Major Hub'},\n",\n        "    'Maradana': {'lat': 6.9271, 'lon': 79.8612, 'type': 'Major Hub'},\n",\n        "    'Pettah': {'lat': 6.9387, 'lon': 79.8542, 'type': 'Major Hub'},\n",\n        "    'Kandy': {'lat': 7.2906, 'lon': 80.6337, 'type': 'Major Hub'},\n",\n        "    'Galle': {'lat': 6.0535, 'lon': 80.2210, 'type': 'Regional Hub'},\n",\n        "    'Jaffna': {'lat': 9.6615, 'lon': 80.0255, 'type': 'Regional Hub'},\n",\n        "    'Negombo': {'lat': 7.2008, 'lon': 79.8358, 'type': 'Regional Hub'},\n",\n        "    'Katunayake Airport': {'lat': 7.1808, 'lon': 79.8841, 'type': 'Airport Hub'},\n",\n        "    'Matara': {'lat': 5.9549, 'lon': 80.5550, 'type': 'Regional Hub'},\n",\n        "    'Anuradhapura': {'lat': 8.3114, 'lon': 80.4037, 'type': 'Regional Hub'},\n",\n        "    'Batticaloa': {'lat': 7.7310, 'lon': 81.6747, 'type': 'Regional Hub'},\n",\n        "    'Trincomalee': {'lat': 8.5874, 'lon': 81.2152, 'type': 'Regional Hub'}\n",\n        "}\n",\n        "HUB_NAMES = list(SRI_LANKA_HUBS.keys())\n",\n        "\n",\n        "print(f\"üöå Transport Modes: {len(TRANSPORT_MODES)}\")\n",\n        "print(f\"üìç Major Hubs: {len(SRI_LANKA_HUBS)}\")"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## üìä Dataset Generation"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# üåßÔ∏è Weather Generation Function\n",\n        "def generate_sri_lanka_weather(timestamp):\n",\n        "    ts = pd.Timestamp(timestamp).to_pydatetime()\n",\n        "    month, hour = ts.month, ts.hour\n",\n        "    \n",\n        "    if 5 <= month <= 9:  # Yala\n",\n        "        conditions = ['Heavy Rain', 'Moderate Rain', 'Light Rain', 'Cloudy', 'Clear']\n",\n        "        weights = [0.25, 0.30, 0.25, 0.15, 0.05]\n",\n        "        base_temp, base_humidity = np.random.normal(28, 2), np.random.normal(80, 5)\n",\n        "    elif month >= 10 or month <= 1:  # Maha\n",\n        "        conditions = ['Heavy Rain', 'Moderate Rain', 'Light Rain', 'Cloudy', 'Clear']\n",\n        "        weights = [0.20, 0.30, 0.30, 0.15, 0.05]\n",\n        "        base_temp, base_humidity = np.random.normal(27, 2), np.random.normal(75, 5)\n",\n        "    else:  # Inter-monsoon\n",\n        "        conditions = ['Clear', 'Partly Cloudy', 'Cloudy', 'Light Rain', 'Moderate Rain']\n",\n        "        weights = [0.35, 0.30, 0.20, 0.10, 0.05]\n",\n        "        base_temp, base_humidity = np.random.normal(30, 2), np.random.normal(70, 5)\n",\n        "    \n",\n        "    if 6 <= hour <= 10: base_temp -= 2\n",\n        "    elif 11 <= hour <= 15: base_temp += 3\n",\n        "    elif 16 <= hour <= 19: base_temp += 1\n",\n        "    else: base_temp -= 3\n",\n        "    \n",\n        "    weather = np.random.choice(conditions, p=weights)\n",\n        "    wind = np.random.exponential(15) if 'Rain' in weather else np.random.exponential(8)\n",\n        "    return weather, round(np.clip(base_temp, 20, 38), 1), round(np.clip(base_humidity, 50, 95), 1), round(wind, 1)\n",\n        "\n",\n        "def calculate_congestion(hour, weather, transport_mode, is_weekend):\n",\n        "    base = 30\n",\n        "    if hour in [7,8,9,17,18,19]: base += 35\n",\n        "    elif hour in range(10, 17): base += 20\n",\n        "    elif hour in [20,21,22]: base += 10\n",\n        "    else: base += 5\n",\n        "    \n",\n        "    if weather == 'Heavy Rain': base += 25\n",\n        "    elif weather == 'Moderate Rain': base += 15\n",\n        "    elif weather == 'Light Rain': base += 10\n",\n        "    \n",\n        "    if transport_mode in ['SLTB Bus', 'Private Bus']: base += 10\n",\n        "    elif transport_mode == 'Three-Wheeler (Tuk-tuk)': base += 5\n",\n        "    \n",\n        "    if is_weekend: base *= 0.7\n",\n        "    return np.clip(base + np.random.normal(0, 8), 0, 100)\n",\n        "\n",\n        "print(\"‚úÖ Functions defined\")"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# üìä Generate Dataset\n",\n        "print(\"üîÑ Generating 75,000 records...\")\n",\n        "np.random.seed(42)\n",\n        "num_records = 75000\n",\n        "start_date = datetime(2023, 6, 1)\n",\n        "timestamps = [start_date + timedelta(hours=np.random.randint(0, 4320)) for _ in range(num_records)]\n",\n        "\n",\n        "records = []\n",\n        "for i, ts in enumerate(timestamps):\n",\n        "    if i % 25000 == 0: print(f\"   Progress: {i/num_records*100:.0f}%\")\n",\n        "    \n",\n        "    mode = np.random.choice(TRANSPORT_MODES)\n",\n        "    origin = np.random.choice(HUB_NAMES)\n",\n        "    dest = np.random.choice([h for h in HUB_NAMES if h != origin])\n",\n        "    weather, temp, humidity, wind = generate_sri_lanka_weather(ts)\n",\n        "    is_weekend = ts.weekday() >= 5\n",\n        "    congestion = calculate_congestion(ts.hour, weather, mode, is_weekend)\n",\n        "    \n",\n        "    if mode == 'Three-Wheeler (Tuk-tuk)': passengers = np.random.randint(1, 4)\n",\n        "    elif mode == 'Taxi (PickMe/Uber)': passengers = np.random.randint(1, 5)\n",\n        "    elif mode in ['SLTB Bus', 'Private Bus']: passengers = np.random.randint(10, 80)\n",\n        "    elif mode == 'Train (Sri Lanka Railways)': passengers = np.random.randint(50, 300)\n",\n        "    else: passengers = np.random.randint(20, 150)\n",\n        "    \n",\n        "    distance = np.random.uniform(5, 200)\n",\n        "    travel_time = distance / (40 - congestion * 0.2) * 60\n",\n        "    delay = np.random.exponential(20 if weather == 'Heavy Rain' else 15 if congestion > 70 else 5)\n",\n        "    \n",\n        "    if mode == 'Three-Wheeler (Tuk-tuk)': fare = distance * np.random.uniform(80, 120)\n",\n        "    elif mode == 'Taxi (PickMe/Uber)': fare = distance * np.random.uniform(100, 150)\n",\n        "    elif mode in ['SLTB Bus', 'Private Bus']: fare = distance * np.random.uniform(3, 8)\n",\n        "    elif mode == 'Train (Sri Lanka Railways)': fare = distance * np.random.uniform(5, 15)\n",\n        "    else: fare = distance * np.random.uniform(10, 25)\n",\n        "    \n",\n        "    records.append({'timestamp': ts, 'transport_mode': mode, 'origin': origin, 'destination': dest,\n",\n        "                    'passengers': passengers, 'distance_km': round(distance, 2),\n",\n        "                    'travel_time_min': round(travel_time, 2), 'delay_min': round(delay, 2),\n",\n        "                    'fare_lkr': round(fare, 2), 'fuel_consumption_l': round(distance * np.random.uniform(0.05, 0.15), 2),\n",\n        "                    'weather': weather, 'temperature_c': temp, 'humidity_percent': humidity,\n",\n        "                    'wind_speed_kmh': wind, 'congestion_index': round(congestion, 2), 'is_weekend': is_weekend})\n",\n        "\n",\n        "df = pd.DataFrame(records)\n",\n        "df['hour'] = df['timestamp'].dt.hour\n",\n        "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",\n        "df['month'] = df['timestamp'].dt.month\n",\n        "df['date'] = df['timestamp'].dt.date\n",\n        "df['congestion_level'] = pd.cut(df['congestion_index'], bins=[0, 40, 60, 80, 100], labels=['Low', 'Moderate', 'High', 'Severe'])\n",\n        "\n",\n        "print(f\"\n‚úÖ Generated {len(df):,} records\")"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## üìã Dataset Overview"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "print(\"="*70)\n",\n        "print(\"üìä DATASET OVERVIEW\")\n",\n        "print(\"="*70)\n",\n        "print(f\"üìè Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",\n        "print(f\"üìÖ Period: {df['timestamp'].min().strftime('%Y-%m-%d')} to {df['timestamp'].max().strftime('%Y-%m-%d')}\")\n",\n        "print(\"\nüöå TRANSPORT MODES:\")\n",\n        "for mode, count in df['transport_mode'].value_counts().items():\n",\n        "    print(f\"   {mode}: {count:,} ({count/len(df)*100:.1f}%)\")\n",\n        "print(\"\nüå§Ô∏è WEATHER:\")\n",\n        "for w, c in df['weather'].value_counts().items():\n",\n        "    print(f\"   {w}: {c:,} ({c/len(df)*100:.1f}%)\")\n",\n        "print(\"\nüö¶ CONGESTION LEVELS:\")\n",\n        "for lvl, c in df['congestion_level'].value_counts().items():\n",\n        "    print(f\"   {lvl}: {c:,} ({c/len(df)*100:.1f}%)\")"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# üìä Distribution Plots\n",\n        "fig = make_subplots(rows=2, cols=3, subplot_titles=('Congestion', 'Distance', 'Delay', 'Temperature', 'Passengers', 'Fare'))\n",\n        "fig.add_trace(go.Histogram(x=df['congestion_index'], marker_color='#FF6B6B', nbinsx=30), row=1, col=1)\n",\n        "fig.add_trace(go.Histogram(x=df['distance_km'], marker_color='#4ECDC4', nbinsx=30), row=1, col=2)\n",\n        "fig.add_trace(go.Histogram(x=df['delay_min'], marker_color='#FFE66D', nbinsx=30), row=1, col=3)\n",\n        "fig.add_trace(go.Histogram(x=df['temperature_c'], marker_color='#FF8C42', nbinsx=30), row=2, col=1)\n",\n        "fig.add_trace(go.Histogram(x=df['passengers'], marker_color='#95E1D3', nbinsx=30), row=2, col=2)\n",\n        "fig.add_trace(go.Histogram(x=df['fare_lkr'], marker_color='#A8E6CF', nbinsx=30), row=2, col=3)\n",\n        "fig.update_layout(title='üìä Feature Distributions', showlegend=False, height=600, template='plotly_white')\n",\n        "fig.show()"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## üîó Correlation Matrix"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "num_cols = ['passengers', 'distance_km', 'travel_time_min', 'delay_min', 'fare_lkr',\n",\n        "            'fuel_consumption_l', 'temperature_c', 'humidity_percent', 'wind_speed_kmh', 'congestion_index', 'hour']\n",\n        "corr = df[num_cols].corr()\n",\n        "\n",\n        "fig = go.Figure(data=go.Heatmap(z=corr.values, x=corr.columns, y=corr.columns,\n",\n        "                                 colorscale='RdBu_r', zmid=0, text=corr.values.round(2),\n",\n        "                                 texttemplate='%{text}', textfont={'size': 9}))\n",\n        "fig.update_layout(title='üîó Correlation Matrix', height=700, width=800, template='plotly_white')\n",\n        "fig.show()\n",\n        "\n",\n        "print(\"\nüìä Correlations with Congestion:\")\n",\n        "for feat, val in corr['congestion_index'].sort_values(ascending=False).items():\n",\n        "    if feat != 'congestion_index': print(f\"   {feat}: {val:+.3f}\")"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "## ‚öôÔ∏è Feature Engineering"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "print(\"‚öôÔ∏è Creating features...\")\n",\n        "df['is_peak_hour'] = df['hour'].isin([7,8,9,17,18,19]).astype(int)\n",\n        "df['is_working_hour'] = df['hour'].between(9, 17).astype(int)\n",\n        "weather_sev = {'Clear': 0, 'Partly Cloudy': 1, 'Cloudy': 2, 'Light Rain': 3, 'Moderate Rain': 4, 'Heavy Rain': 5}\n",\n        "df['weather_severity'] = df['weather'].map(weather_sev)\n",\n        "df['is_yala_monsoon'] = df['month'].isin([5,6,7,8,9]).astype(int)\n",\n        "df['is_maha_monsoon'] = df['month'].isin([10,11,12,1]).astype(int)\n",\n        "\n",\n        "le_mode, le_origin, le_dest = LabelEncoder(), LabelEncoder(), LabelEncoder()\n",\n        "df['mode_encoded'] = le_mode.fit_transform(df['transport_mode'])\n",\n        "df['origin_encoded'] = le_origin.fit_transform(df['origin'])\n",\n        "df['dest_encoded'] = le_dest.fit_transform(df['destination'])\n",\n        "df['weather_hour_interaction'] = df['weather_severity'] * df['is_peak_hour']\n",\n        "\n",\n        "print(f\"‚úÖ Features: {len(df.columns)}\")"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "---\n",\n        "# üéØ OUTCOME 1: Multimodal Transport Coordination"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Sankey Diagram\n",\n        "mode_pairs = df.groupby(['origin', 'transport_mode']).size().reset_index(name='count').nlargest(50, 'count')\n",\n        "nodes = list(set(mode_pairs['origin'].tolist() + mode_pairs['transport_mode'].tolist()))\n",\n        "node_idx = {n: i for i, n in enumerate(nodes)}\n",\n        "\n",\n        "fig = go.Figure(go.Sankey(\n",\n        "    node=dict(pad=15, thickness=20, label=nodes),\n",\n        "    link=dict(source=[node_idx[o] for o in mode_pairs['origin']],\n",\n        "              target=[node_idx[m] for m in mode_pairs['transport_mode']],\n",\n        "              value=mode_pairs['count'].tolist())\n",\n        "))\n",\n        "fig.update_layout(title='üîÑ Passenger Flow: Hubs ‚Üí Transport Modes', height=600)\n",\n        "fig.show()"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Hub Transfer Heatmap\n",\n        "transfer = df.groupby(['origin', 'destination'])['passengers'].sum().reset_index()\n",\n        "pivot = transfer.pivot(index='origin', columns='destination', values='passengers').fillna(0)\n",\n        "\n",\n        "fig = go.Figure(go.Heatmap(z=pivot.values, x=pivot.columns, y=pivot.index, colorscale='Viridis'))\n",\n        "fig.update_layout(title='üó∫Ô∏è Hub Transfer Patterns', height=600, template='plotly_white')\n",\n        "fig.show()\n",\n        "\n",\n        "print(\"\nüìä Top 10 Routes:\")\n",\n        "for i, r in enumerate(transfer.nlargest(10, 'passengers').itertuples(), 1):\n",\n        "    print(f\"   {i}. {r.origin} ‚Üí {r.destination}: {r.passengers:,}\")"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Mode by Hub\n",\n        "hub_mode = df.groupby(['origin', 'transport_mode']).size().reset_index(name='count')\n",\n        "fig = px.bar(hub_mode, x='origin', y='count', color='transport_mode', title='üöå Mode Distribution by Hub', height=500)\n",\n        "fig.update_layout(xaxis_tickangle=-45, template='plotly_white')\n",\n        "fig.show()"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "---\n",\n        "# üéØ OUTCOME 2: Traffic Congestion Prediction (Random Forest)"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Prepare ML Data\n",\n        "features = ['hour', 'day_of_week', 'is_weekend', 'distance_km', 'passengers', 'weather_severity',\n",\n        "            'temperature_c', 'humidity_percent', 'wind_speed_kmh', 'mode_encoded',\n",\n        "            'origin_encoded', 'dest_encoded', 'is_peak_hour', 'is_yala_monsoon', 'is_maha_monsoon', 'weather_hour_interaction']\n",\n        "\n",\n        "X = df[features]\n",\n        "y_reg = df['congestion_index']\n",\n        "le_cong = LabelEncoder()\n",\n        "y_class = le_cong.fit_transform(df['congestion_level'])\n",\n        "\n",\n        "X_train, X_test, y_reg_train, y_reg_test = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",\n        "_, _, y_class_train, y_class_test = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",\n        "\n",\n        "print(f\"‚úÖ Train: {len(X_train):,} | Test: {len(X_test):,}\")"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Train Random Forest Regressor\n",\n        "print(\"üå≥ Training Random Forest Regressor...\")\n",\n        "rf_reg = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",\n        "rf_reg.fit(X_train, y_reg_train)\n",\n        "\n",\n        "y_pred_train = rf_reg.predict(X_train)\n",\n        "y_pred_test = rf_reg.predict(X_test)\n",\n        "\n",\n        "train_r2, test_r2 = r2_score(y_reg_train, y_pred_train), r2_score(y_reg_test, y_pred_test)\n",\n        "train_rmse, test_rmse = np.sqrt(mean_squared_error(y_reg_train, y_pred_train)), np.sqrt(mean_squared_error(y_reg_test, y_pred_test))\n",\n        "cv_scores = cross_val_score(rf_reg, X_train, y_reg_train, cv=5, scoring='r2', n_jobs=-1)\n",\n        "\n",\n        "print(\"\n\" + \"="*60)\n",\n        "print(\"üìä RANDOM FOREST REGRESSOR RESULTS\")\n",\n        "print(\"="*60)\n",\n        "print(f\"R¬≤ Score:  Train={train_r2:.4f} | Test={test_r2:.4f}\")\n",\n        "print(f\"RMSE:      Train={train_rmse:.4f} | Test={test_rmse:.4f}\")\n",\n        "print(f\"CV (5-fold): {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Prediction vs Actual\n",\n        "sample = np.random.choice(len(y_reg_test), 2000, replace=False)\n",\n        "fig = go.Figure()\n",\n        "fig.add_trace(go.Scatter(x=y_reg_test.iloc[sample], y=y_pred_test[sample], mode='markers',\n",\n        "                          marker=dict(color='#667EEA', opacity=0.5), name='Predictions'))\n",\n        "fig.add_trace(go.Scatter(x=[0,100], y=[0,100], mode='lines', line=dict(color='red', dash='dash'), name='Perfect'))\n",\n        "fig.update_layout(title=f'üìä Predicted vs Actual (R¬≤={test_r2:.4f})', xaxis_title='Actual', yaxis_title='Predicted',\n",\n        "                  height=500, template='plotly_white')\n",\n        "fig.show()"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Feature Importance\n",\n        "importance = pd.DataFrame({'feature': features, 'importance': rf_reg.feature_importances_}).sort_values('importance', ascending=True)\n",\n        "\n",\n        "fig = go.Figure(go.Bar(x=importance['importance'], y=importance['feature'], orientation='h', marker_color='#667EEA'))\n",\n        "fig.update_layout(title='üéØ Feature Importance', height=500, template='plotly_white')\n",\n        "fig.show()\n",\n        "\n",\n        "print(\"\nüîù Top 5 Features:\")\n",\n        "for i, r in enumerate(importance.nlargest(5, 'importance').itertuples(), 1):\n",\n        "    print(f\"   {i}. {r.feature}: {r.importance:.4f}\")"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Random Forest Classifier\n",\n        "print(\"üå≥ Training Classifier...\")\n",\n        "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n",\n        "rf_clf.fit(X_train, y_class_train)\n",\n        "y_clf_pred = rf_clf.predict(X_test)\n",\n        "\n",\n        "acc, f1 = accuracy_score(y_class_test, y_clf_pred), f1_score(y_class_test, y_clf_pred, average='weighted')\n",\n        "print(f\"\nüéØ Accuracy: {acc:.4f}\")\n",\n        "print(f\"üìä F1 Score: {f1:.4f}\")\n",\n        "print(\"\n" + classification_report(y_class_test, y_clf_pred, target_names=le_cong.classes_))"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Confusion Matrix\n",\n        "cm = confusion_matrix(y_class_test, y_clf_pred)\n",\n        "fig = go.Figure(go.Heatmap(z=cm, x=le_cong.classes_, y=le_cong.classes_, colorscale='Blues',\n",\n        "                            text=cm, texttemplate='%{text}', textfont={'size': 14}))\n",\n        "fig.update_layout(title='üìä Confusion Matrix', xaxis_title='Predicted', yaxis_title='Actual',\n",\n        "                  height=450, width=500, template='plotly_white')\n",\n        "fig.show()"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "---\n",\n        "# üéØ OUTCOME 3: Operational Insights Dashboard"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# KPI Dashboard\n",\n        "total_pax = df['passengers'].sum()\n",\n        "total_rev = df['fare_lkr'].sum()\n",\n        "avg_delay = df['delay_min'].mean()\n",\n        "avg_cong = df['congestion_index'].mean()\n",\n        "on_time = (df['delay_min'] < 5).sum() / len(df) * 100\n",\n        "\n",\n        "fig = make_subplots(rows=1, cols=4, specs=[[{'type': 'indicator'}]*4],\n",\n        "                    subplot_titles=['Total Passengers', 'Revenue (M LKR)', 'On-Time %', 'Avg Congestion'])\n",\n        "\n",\n        "fig.add_trace(go.Indicator(mode='number', value=total_pax, number={'font': {'size': 36}}), row=1, col=1)\n",\n        "fig.add_trace(go.Indicator(mode='number', value=total_rev/1e6, number={'font': {'size': 36}, 'suffix': 'M'}), row=1, col=2)\n",\n        "fig.add_trace(go.Indicator(mode='gauge+number', value=on_time, gauge={'axis': {'range': [0, 100]},\n",\n        "              'bar': {'color': 'green' if on_time > 70 else 'red'}}), row=1, col=3)\n",\n        "fig.add_trace(go.Indicator(mode='gauge+number', value=avg_cong, gauge={'axis': {'range': [0, 100]},\n",\n        "              'bar': {'color': 'red' if avg_cong > 60 else 'green'}}), row=1, col=4)\n",\n        "\n",\n        "fig.update_layout(title='üìà Operational KPI Dashboard', height=300)\n",\n        "fig.show()"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Hourly Patterns\n",\n        "hourly = df.groupby('hour').agg({'congestion_index': 'mean', 'delay_min': 'mean', 'passengers': 'sum'}).reset_index()\n",\n        "\n",\n        "fig = make_subplots(rows=1, cols=3, subplot_titles=['Congestion by Hour', 'Delay by Hour', 'Passengers by Hour'])\n",\n        "fig.add_trace(go.Bar(x=hourly['hour'], y=hourly['congestion_index'], marker_color='#FF6B6B'), row=1, col=1)\n",\n        "fig.add_trace(go.Bar(x=hourly['hour'], y=hourly['delay_min'], marker_color='#FFE66D'), row=1, col=2)\n",\n        "fig.add_trace(go.Bar(x=hourly['hour'], y=hourly['passengers'], marker_color='#4ECDC4'), row=1, col=3)\n",\n        "fig.update_layout(title='‚è∞ Hourly Patterns', showlegend=False, height=400, template='plotly_white')\n",\n        "fig.show()"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "---\n",\n        "# üéØ OUTCOME 4: Weather-Driven Route Optimization"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Weather Impact Analysis\n",\n        "weather_impact = df.groupby('weather').agg({'congestion_index': 'mean', 'delay_min': 'mean', 'passengers': 'sum'}).reset_index()\n",\n        "\n",\n        "fig = make_subplots(rows=1, cols=2, subplot_titles=['Congestion by Weather', 'Delay by Weather'])\n",\n        "fig.add_trace(go.Bar(x=weather_impact['weather'], y=weather_impact['congestion_index'], marker_color='#FF6B6B'), row=1, col=1)\n",\n        "fig.add_trace(go.Bar(x=weather_impact['weather'], y=weather_impact['delay_min'], marker_color='#4ECDC4'), row=1, col=2)\n",\n        "fig.update_layout(title='üåßÔ∏è Weather Impact on Transport', showlegend=False, height=400, template='plotly_white')\n",\n        "fig.show()\n",\n        "\n",\n        "print(\"\nüåßÔ∏è Weather Impact Summary:\")\n",\n        "for _, r in weather_impact.iterrows():\n",\n        "    print(f\"   {r['weather']}: Congestion={r['congestion_index']:.1f}%, Delay={r['delay_min']:.1f}min\")"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "# Monsoon Season Comparison\n",\n        "df['season'] = df.apply(lambda x: 'Yala' if x['is_yala_monsoon'] else ('Maha' if x['is_maha_monsoon'] else 'Inter'), axis=1)\n",\n        "season_stats = df.groupby('season').agg({'congestion_index': 'mean', 'delay_min': 'mean'}).reset_index()\n",\n        "\n",\n        "fig = px.bar(season_stats, x='season', y=['congestion_index', 'delay_min'], barmode='group',\n",\n        "             title='üå¥ Monsoon Season Impact', labels={'value': 'Value', 'variable': 'Metric'})\n",\n        "fig.update_layout(height=400, template='plotly_white')\n",\n        "fig.show()"\n      ]\n    },\n    {\n      "cell_type": "markdown",\n      "metadata": {},\n      "source": [\n        "---\n",\n        "# üí° Decision Support Summary"\n      ]\n    },\n    {\n      "cell_type": "code",\n      "execution_count": null,\n      "metadata": {},\n      "outputs": [],\n      "source": [\n        "print(\"="*70)\n",\n        "print(\"üí° DECISION SUPPORT RECOMMENDATIONS\")\n",\n        "print(\"="*70)\n",\n        "print(\"\nüîÑ MULTIMODAL COORDINATION:\")\n",\n        "print(\"   ‚Ä¢ Increase bus frequency at high-traffic hubs\")\n",\n        "print(\"   ‚Ä¢ Create three-wheeler integration zones near stations\")\n",\n        "print(\"   ‚Ä¢ Coordinate train and bus schedules at major terminals\")\n",\n        "\n",\n        "print(\"\nüö¶ CONGESTION MANAGEMENT:\")\n",\n        "print(f\"   ‚Ä¢ Model predicts congestion with R¬≤={test_r2:.2f} accuracy\")\n",\n        "print(f\"   ‚Ä¢ Peak hours (7-9, 17-19) show highest congestion\")\n",\n        "print(\"   ‚Ä¢ Deploy extra resources during predicted high congestion\")\n",\n        "\n",\n        "print(\"\nüåßÔ∏è WEATHER RESPONSE:\")\n",\n        "print(\"   ‚Ä¢ Heavy rain increases congestion by ~25%\")\n",\n        "print(\"   ‚Ä¢ Pre-position resources before monsoon seasons\")\n",\n        "print(\"   ‚Ä¢ Activate alternate routes during severe weather\")\n",\n        "\n",\n        "print(\"\nüìà OPERATIONAL IMPROVEMENTS:\")\n",\n        "print(f\"   ‚Ä¢ Current on-time performance: {on_time:.1f}%\")\n",\n        "print(f\"   ‚Ä¢ Average delay: {avg_delay:.1f} minutes\")\n",\n        "print(\"   ‚Ä¢ Focus on reducing delays during peak hours\")\n",\n        "print(\"\n‚úÖ Dashboard analysis complete!\")"\n      ]\n    }\n  ],\n  "metadata": {\n    "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},\n    "language_info": {"name": "python", "version": "3.9.0"}\n  },\n  "nbformat": 4,\n  "nbformat_minor": 4\n}